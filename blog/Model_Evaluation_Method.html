<!doctype html>



  


<html class="theme-next pisces use-motion">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">



<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">












  
  
  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.0.1" rel="stylesheet" type="text/css">


  <meta name="keywords" content="算法,模型,评价方法,">








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.1">






<meta name="description" content="本文由 简悦 SimpRead 转码， 原文地址 https://www.jianshu.com/p/b4d40760156c?utm_campaign=maleskine&amp;amp;utm_content=note&amp;amp;utm_medium=seo_notes&amp;amp;utm_source=recommendation  第五章 模型评价方法5.1 模型的评价方法介绍5.1.1~5 accu">
<meta name="keywords" content="算法,模型,评价方法">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习算法模型评价方法">
<meta property="og:url" content="https://luisstruggle.github.io/blog/Model_Evaluation_Method.html">
<meta property="og:site_name" content="奋斗的青春">
<meta property="og:description" content="本文由 简悦 SimpRead 转码， 原文地址 https://www.jianshu.com/p/b4d40760156c?utm_campaign=maleskine&amp;amp;utm_content=note&amp;amp;utm_medium=seo_notes&amp;amp;utm_source=recommendation  第五章 模型评价方法5.1 模型的评价方法介绍5.1.1~5 accu">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/5401649-31681a77fe06743a.png">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/5401649-5732a172075a2acf.png">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/5401649-050b7181900d2689.png">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/5401649-a82fe9aca8a452bd.png">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/5401649-da5965368bfdca12.png">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/5401649-d869f3c35958ca9c.png">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/5401649-549ed1cc96782d69.png">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/5401649-36c521be4760dac4.png">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/5401649-9da3f4af2c627e82.png">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/5401649-476412c4b8b8e1b9.png">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/5401649-607039003ac26948.png">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/5401649-4efc250b7dd2577a.png">
<meta property="og:updated_time" content="2020-01-09T11:17:01.786Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习算法模型评价方法">
<meta name="twitter:description" content="本文由 简悦 SimpRead 转码， 原文地址 https://www.jianshu.com/p/b4d40760156c?utm_campaign=maleskine&amp;amp;utm_content=note&amp;amp;utm_medium=seo_notes&amp;amp;utm_source=recommendation  第五章 模型评价方法5.1 模型的评价方法介绍5.1.1~5 accu">
<meta name="twitter:image" content="http://upload-images.jianshu.io/upload_images/5401649-31681a77fe06743a.png">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 6311968968739390000,
      author: '博主'
    }
  };
</script>




  <link rel="canonical" href="https://luisstruggle.github.io/blog/Model_Evaluation_Method.html">

  <title> 机器学习算法模型评价方法 | 奋斗的青春 </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">奋斗的青春</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle">【求你将我放在你心上如印记，带在你臂上如戳记。因为爱情如死之坚强，嫉恨如阴间之残忍。】 ——  圣经.雅歌 8.6</p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-commonweal">
          <a href="/404.html" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-heartbeat"></i> <br>
            
            公益
          </a>
        </li>
      

      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                机器学习算法模型评价方法
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2019-11-26T08:30:31+08:00" content="2019-11-26">
              2019-11-26
            </time>
          </span>

          
            <span class="post-category">
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/学习篇/" itemprop="url" rel="index">
                    <span itemprop="name">学习篇</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <blockquote>
<p>本文由 <a href="http://ksria.com/simpread/" target="_blank" rel="noopener">简悦 SimpRead</a> 转码， 原文地址 <a href="https://www.jianshu.com/p/b4d40760156c?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation" target="_blank" rel="noopener">https://www.jianshu.com/p/b4d40760156c?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation</a></p>
</blockquote>
<h2 id="第五章-模型评价方法"><a href="#第五章-模型评价方法" class="headerlink" title="第五章 模型评价方法"></a>第五章 模型评价方法</h2><h3 id="5-1-模型的评价方法介绍"><a href="#5-1-模型的评价方法介绍" class="headerlink" title="5.1 模型的评价方法介绍"></a>5.1 模型的评价方法介绍</h3><p>5.1.1~5 accuracy，precision，recall，F1-score，ROC 曲线</p>
<p>分别画图举例，要说出应用场景，例如什么情况用什么评价标准。</p>
<ul>
<li>混淆矩阵</li>
<li>accuracy（准确率）</li>
<li>precision（精准度），recall（召回率），F1-score（宏观，微观）</li>
<li>ROC 曲线图</li>
</ul>
<a id="more"></a>
<h3 id="5-2-项目实例运用"><a href="#5-2-项目实例运用" class="headerlink" title="5.2 项目实例运用"></a>5.2 项目实例运用</h3><hr>
<p>为了对模型的效果进行评估，需要好的评估方法，还需要衡量模型泛化能力的评价标准。评价指标是机器学习任务中非常重要的一环。不同的机器学习任务有着不同的评价指标，同时同一种机器学习任务也有着不同的评价指标，每个指标的着重点不一样。如分类（classification）、回归（regression）、排序（ranking）、聚类（clustering）、热门主题模型（topic modeling）、推荐（recommendation）等。并且很多指标可以对多种不同的机器学习模型进行评价，如精确率－召回率（precision-recall），可以用在分类、推荐、排序等中。像分类、回归、排序都是监督式机器学习。</p>
<p>不同的机器学习任务有着不同的性能评价指标。例如，在垃圾邮件检测系统中，这个系统本质上是一个二分类问题（区分垃圾邮件 vs 正常邮件），可以使用准确率（Accuracy）、对数损失函数（log-loss）、AUC 等评价方法。在股票预测中，这其实是一个实数序列数据预测问题，可以使用平方根误差（root mean square error， RMSE）等指标；又如在搜索引擎中进行与查询相关的项目排序中，可以使用精确率－召回率（precision-recall）等等。</p>
<p>在对比不同模型的能力时，使用不同的评价指标可能会导致不同的结果，这就说明：模型的好坏是相对的，好的模型不仅仅取决于数据和算法，还取决于场景需求。</p>
<p>本章主要介绍分类学习中的常用的评价指标。</p>
<h3 id="5-1-1-准确率"><a href="#5-1-1-准确率" class="headerlink" title="5.1.1 准确率"></a>5.1.1 准确率</h3><p>这是分类任务常见的评价标准，定义如下：<strong>准确率</strong>又称查准率（Precision），为分类任务中分类正确的样本数在总样本数中所占比例，错误率为分类错误的样本数在总样本中所占比例。准确率的计算方法为：</p>
<p><img src="http://upload-images.jianshu.io/upload_images/5401649-31681a77fe06743a.png" alt></p>
<p>简单来说，在这样的一个应用场景中，某个社团有男的和女的两类，分类器根据自己的判断，将社团中的人分为男女两类。准确率需要得到的是该分类器判断正确的人占总人数的比例。显然，我们可以得到：假设分类器对 100 人的性别进行判断，而其中 60 人的性别判定正确，则该分类器的准确率就是 60 %（60 / 100）。</p>
<p>其计算代码为：</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">from sklearn.metrics import accuracy_score</span><br><span class="line">y_pred = [<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>]</span><br><span class="line">y_true = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">accuracy_score(y_true, y_pred)</span><br></pre></td></tr></table></figure>
<p>输出为：</p>
<p>根据准确率这一评价方法，我们可以在一些场景中得到一个分类器是否有效，但它并不总是能有效的评价一个分类器的工作。这样的度量错误掩盖了样例如何被分错的事实。例如，在正负样本不平衡的情况下，准确率这个评价指标有很大的缺陷。比如在互联网广告里面，点击的数量是很少的，一般只有千分之几，如果用 Accuracy，即使全部预测成负类（不点击）Accuracy 可以达到 99% 以上，这样可以完爆其它很多分类器辛辛苦苦算的值，但是这个算法显然不是被需求所期待的，那怎么解决呢？这就是 precision、recall 和 f1-score 的出现的原因了。</p>
<h3 id="5-1-2-精度"><a href="#5-1-2-精度" class="headerlink" title="5.1.2 精度"></a>5.1.2 精度</h3><p>准确率和错误率虽然常见，但是不一定能很好的满足需求。<strong>精度（presicion）</strong>又可以称为查准率。其中精度是检索出相关文档数与检索出的文档总数的比率，衡量的是检索系统的查准率。直观地来理解，精度是分类器的标签不能被标记为正的样本为负的能力。</p>
<p>对于一个二分类问题，可以将训练集的真实类别与模型预测得到的类别组合，得到以下四种类型：TP（True Positive），TN（True Nagetive），FP（False Positive），FN（False Nagetive）。所有的训练集中的样例都可以被分为这四种类型，组成一个混淆矩阵。</p>
<p><strong>混淆矩阵</strong>（Confusion Matrix）是一个普遍适用的工具，它可以帮助我们更好地了解分类中的错误。混淆矩阵也称误差矩阵，是表示精度评价的一种标准格式，用 n 行 n 列的矩阵形式来表示，是对有监督学习分类算法准确率进行评估的工具。通过将模型预测的数据与测试数据进行对比，使用准确率，覆盖率和命中率等指标对模型的分类效果进行度量。 混淆矩阵是一个 N X N 矩阵，N 为分类的个数。假如我们面对的是一个二分类问题，也就是 N＝2，我们就得到一个 2 X 2 矩阵，如下表所示。</p>
<table>
<thead>
<tr>
<th>真实类别 / 预测类别</th>
<th>正例</th>
<th>负例</th>
</tr>
</thead>
<tbody>
<tr>
<td>正例</td>
<td>TP</td>
<td>FP</td>
</tr>
<tr>
<td>负例</td>
<td>FN</td>
<td>FN</td>
</tr>
</tbody>
</table>
<p>混淆矩阵中，各个内容的含义如下：</p>
<ul>
<li>True Positive 简称 TP，表示测试集中是 Positive，模型预测结果是 Positive 的数据条目，即将正例判断为正例。</li>
<li>False Positive 简称 FP，表示测试集中是 Negative，模型预测结果是 Positive 的数据条目。</li>
<li>False Negative 简称 FN，表示测试集中是 Positive，模型预测结果是 Negative 的数据条目。</li>
<li>True Negative 简称 TN，表示测试集中是 Negative，模型预测结果是 Negative 的数据条目。</li>
</ul>
<p>对于一个 m 分的标准分类问题来说，也可以定义如上表所示 m×m 的 m 分混淆矩阵和每一个类属的 Recall、Precision、F-measure 和 Accuracy 值。</p>
<p>从混淆矩阵中，可以衍生出各种评价的指标。（图片 from 维基百科）</p>
<p><img src="http://upload-images.jianshu.io/upload_images/5401649-5732a172075a2acf.png" alt></p>
<p>混淆矩阵的代码实现如下：</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0<span class="selector-class">.5</span></span><br></pre></td></tr></table></figure>
<p>对于二分类问题（ binary problems ），我们可以得到 true negatives（真 negatives）, false positives（假 positives）, false negatives（假 negatives） 和 true positives（真 positives） 的数量如下:</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.metrics import confusion_matrix</span><br><span class="line">y_true = [<span class="number">2</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line">y_pred = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">2</span>]</span><br><span class="line">confusion_matrix(y_true, y_pred)</span><br></pre></td></tr></table></figure>
<h3 id="5-1-3-召回"><a href="#5-1-3-召回" class="headerlink" title="5.1.3 召回"></a>5.1.3 召回</h3><p><strong>召回率</strong>又称查全率（Recall），召回率是指分类器分类正确的正样本个数占所有的正样本个数的比例。直观的理解，召回率是指分类器查找所有正样本的能力。举例来说，召回率是指检索出的相关文档数和文档库中所有的相关文档数的比率，衡量的是检索系统的查全率。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/5401649-050b7181900d2689.png" alt></p>
<p>计算代码为：</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">array([[<span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>]])</span><br></pre></td></tr></table></figure>
<p>输出为：</p>
<p>精度和召回往往是一对矛盾的变量。一般来说，当精度高时，召回率会偏低；而当召回率高时，精度会偏低。如果按照预测为正例的概率大小进行排序，按照顺序依次进行预测，得到精度和召回，可以绘制一条 P-R 曲线。P-R 图可以直观地展示样本整体的精度和召回的情况。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/5401649-a82fe9aca8a452bd.png" alt></p>
<p>构造一个高正确率或高召回率的分类器是很容易的，但是很难保证两者同时成立。如果将所有的样例都判为正例，那么召回率达到 100% 同时正确率很低。构建一个同时使正确率和召回率最大的分类器是具有挑战性的。</p>
<h3 id="5-1-4-F1"><a href="#5-1-4-F1" class="headerlink" title="5.1.4 F1"></a>5.1.4 F1</h3><p>为了综合考虑精度和召回，也常常用 F1 度量。<strong>F1-score</strong> 基于精度和召回的调和平均来定义，它的值更接近于 Precision 与 Recall 中较小的值。其计算方法为：</p>
<p><img src="http://upload-images.jianshu.io/upload_images/5401649-da5965368bfdca12.png" alt></p>
<p>其中，P 为准确率，R 为召回率。精确率和准确率都高的情况下，F1 值也会高。P 和 R 指标有时候会出现的矛盾的情况，这样就需要综合考虑他们。F1-score 值达到其最佳值 1 ，其最差分数为 0 。</p>
<p>除了 F1 之外，还有一个更普遍的计算公式：<br>F- = (α^2+1) PR/(α^2)P + R)</p>
<p>也可以直接利用 sklearn 里的函数计算 F1-score：</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.metrics import recall_score</span><br><span class="line">y_true = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]</span><br><span class="line">y_pred = [<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line">recall_score(y_true, y_pred, average='macro')</span><br></pre></td></tr></table></figure>
<p>输出为：</p>
<p>公式里的α（α&gt;0）是用于衡量查全率对查准率的相对重要性。当α=1 时即为标准的 F1(基于 P、R 的调和平均)；当α&gt;1 时，查全率具有更大的影响；当α&lt;1 时查准率具有更大影响。</p>
<p>其中α=2 和α=0.5 是除了 F1 之外，两个常用的 F-measure：<br>（1）当α=2，则表示 recall 的影响要大于 precision；<br>（2）当α=0.5，则表示 precision 的影响要大于 recall.</p>
<p>F1 值在实际应用中较常用。相比于 P、R 的算术平均和几何平均（G-mean），F1 值更重视较小值（不平衡数据下的稀有类），这也说明 F1 对于衡量数据更有利。</p>
<h3 id="5-1-5-ROC"><a href="#5-1-5-ROC" class="headerlink" title="5.1.5 ROC"></a>5.1.5 ROC</h3><p>另一个用于分类模型的评价指标的工具是 ROC 曲线（ROC curve），ROC 全称是受试者工作特征（receiver operating characteristic），它最早是在二战期间由电气工程师构建雷达系统时使用过，ROC 曲线最早是运用在军事上，后来逐渐运用到医学领域，此后被引入机器学习领域中。<strong>ROC</strong>（Receiver Operating Characteristic）与 P-R 曲线类似，按照预测结果对样例进行排序，按照顺序依次进行预测，计算 TPR 和 FPR，并分别以它为横纵坐标作图，这样就得到了 ROC 曲线。TPR 和 FPR 分别定义为：</p>
<p>召回率 TPR(True Positive Rate) =TP/(TP+FN) ＝ a / (a+b)<br>取伪率 FPR(False Positive Rate) = FP/(FP+TN) = c / (c+d)</p>
<p><img src="http://upload-images.jianshu.io/upload_images/5401649-d869f3c35958ca9c.png" alt></p>
<p>ROC 曲线，图片来自维基百科</p>
<p>在图中的 ROC 曲线中，有几条虚线和一条实线。图中的横轴是取伪率（FPR），Y 轴为召回率（TPR）。ROC 曲线给出的是阈值变化时取伪率和召回率的变化情况，左下角的点所对应的是将所有样例判断为反例的情况，而右上角的点对应的则是将所有样例判断为正例的情况。虚线给出的是随机猜测的结果曲线。</p>
<p>取伪率和召回率这两个指标之间相互制约。通俗地来说，即在 TPR 随着 FPR 递增的情况下，谁增长得更快，快多少的问题。TPR 增长得越快，曲线越往上屈，反映了模型的分类性能就越好。在理想的情况下，最佳的分类起应该尽可能的处于左上角，显而易见，最好的分类器便是 FPR＝0%，TPR＝100%。这就意味着分类器在取伪率很低的同时获得了很高的召回率。例如在垃圾邮件的过滤中，这就相当于过滤掉了所有垃圾邮件，且没有将任何正常邮件误分类为垃圾邮件。但是一般在实践中一个分类器很难会有这么好的效果，即一般 TPR 不等于 1，FPR 不等于 0 的。当正负样本不平衡时，这种模型评价方式比起一般的精确度评价方式的好处尤其显著。</p>
<p>如何描绘 ROC 曲线？如在二分类中，我们需要设定一个阈值，大于阈值分类正类，否则分为负类。因此，我们可以变化阈值，根据不同的阈值进行分类，根据分类结果计算得到 ROC 空间中的一些点，连接这些点就形成 ROC 曲线。ROC 曲线会经过 (0,0) 与(1,1)这两点，实际上这两点的连线形成的 ROC 代表一个随机分类器，一般情况下分类器的 ROC 曲线会在这条对角连线上方。</p>
<p>实际上，通过有限实例产生的 ROC 曲线实际上是一个阶梯函数，该曲线近似于实例数量接近无限时对应的 ROC 曲线。对模型进行评价时，若某 ROC 曲线可以将另一条 ROC 曲线完全包裹，则可以说明效果要好于被包裹的 ROC 曲线，否则，若两条 ROC 曲线存在交叉，则很难评价哪一条曲线更优。</p>
<p>ROC 曲线有个很好的特性：当测试集中的正负样本的分布变化的时候，ROC 曲线能够保持不变。在实际的数据集中经常会出现类不平衡（class imbalance）现象，即负样本比正样本多很多（或者相反），而且测试数据中的正负样本的分布也可能随着时间变化。与 F1 score 的指标相比， ROC 不需要优化每个标签的阈值。</p>
<p>ROC 曲线是通过与参照线进行比较来判断模型的好坏，虽然很直观好用，但这只是一种直觉上的定性分析，当使用 ROC 曲线对分类器进行评价时，如果对多个分类器进行比较时，如果直接使用 ROC 曲线很难去比较，只能通过将 ROC 分别画出来，然后进行肉眼比较，那么这种方法是非常不便的，因此我们需要一种定量的指标去比较，这个指标便是 AUC 了，即 ROC 曲线下的面积，面积越大，分类器的效果越好，AUC 的值介于 0.5 到 1.0 之间。</p>
<p><strong>AUC</strong>（area under curve）即 ROC 曲线下的面积。其含义是随机给定一个正样本和一个负样本，分类器输出该正样本为正的那个概率值比分类器输出该负样本为正的那个概率值要大的可能性。</p>
<p>假设分类器的输出是样本属于正类的 socre（置信度），则 AUC 的物理意义为，任取一对（正、负）样本，正样本的 score 大于负样本的 score 的概率。为了计算 AUC，我们通常是对 ROC 曲线中的多个小矩形的面积进行累加。</p>
<p>计算 AUC 可以直接调用 sklearn：</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0<span class="selector-class">.33</span>...</span><br></pre></td></tr></table></figure>
<p>可得计算结果：</p>
<p>通常，AUC 的值介于 0.5 到 1.0 之间，较大的 AUC 代表了较好的 performance。一个完美的分类器的 AUC 为 1.0。<br>当 0.5&lt;AUC&lt;1，优于随机猜测。这个分类器（模型）妥善设定阈值的话，能有预测价值。<br>当 AUC=0.5，跟随机猜测效果差不多，模型没有预测价值。</p>
<p>ROC 曲线和 AUC 的优势：不受类分布的影响，适合与评估、比较类分布不平衡的数据集。因此 ROC 曲线与 AUC 已被广泛用于医疗决策制定、模式识别和数据挖掘等领域。但是 ROC 和 AUC 仅适合于两类问题 , 对多类问题 , 无法直接应用。</p>
<p>基尼系数应大于 60%，就算好模型。基尼系数经常用于分类问题，其可以直接从 AUC 中得到。其公式为：Gini ＝ 2*AUC － 1</p>
<h3 id="5-1-6-回归模型评价指标"><a href="#5-1-6-回归模型评价指标" class="headerlink" title="5.1.6 回归模型评价指标"></a>5.1.6 回归模型评价指标</h3><p>回归是对连续的实数值进行预测，即输出值是连续的实数值，而分类中是离散值。常用的回归模型的评价指标主要有均方误差根（RMSE）和 R - 平方（R2）。</p>
<p><strong>RMSE</strong>（root mean square error），其又被称为 RMSD（root mean square deviation），是预测值与真实值的误差平方根的均值。其定义如下：</p>
<p><img src="http://upload-images.jianshu.io/upload_images/5401649-549ed1cc96782d69.png" alt></p>
<p>其中，yi 是真实值，yi^ 是预测值，n 是样本数量，使用了欧式距离。</p>
<p>RMSE 的缺点是：对异常点较敏感，如果回归器对某个点的回归值很不理性，那么它的误差则较大，从而会对 RMSE 的值有较大影响，即平均值是非 Robust 的。</p>
<p>其 python 实现代码如下：</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.metrics import f1_score</span><br><span class="line">y_true = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]</span><br><span class="line">y_pred = [<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line">f1_score(y_true, y_pred, average='macro')</span><br></pre></td></tr></table></figure>
<p><strong>R2_score</strong> 是多元回归中的回归平方和占总平方和的比例，它是度量多元回归方程中拟合程度的一个统计量，反映了在因变量 y 的变差中被估计的回归方程所解释的比例。其定义是：</p>
<p><img src="http://upload-images.jianshu.io/upload_images/5401649-36c521be4760dac4.png" alt></p>
<p>其区间通常在（0,1）之间。0 表示不如均值。1 表示完美预测。R 平方越接近 1，表明回归平方和占总平方和的比例越大，回归线与各观测点越接近，用 x 的变化来解释 y 值变差的部分就越多，回归的拟合程度就越好。</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0<span class="selector-class">.26666666666666666</span></span><br></pre></td></tr></table></figure>
<h3 id="5-2-应用"><a href="#5-2-应用" class="headerlink" title="5.2 应用"></a>5.2 应用</h3><p>评价方法在很多 python 包中都有已经写好的函数，以下是 Scikit-learn 中对应的函数名称以及描述：</p>
<table>
<thead>
<tr>
<th>指标</th>
<th>描述</th>
<th>Scikit-learn 函数</th>
</tr>
</thead>
<tbody>
<tr>
<td>Precision</td>
<td>精准度</td>
<td>from sklearn.metrics import precision_score</td>
</tr>
<tr>
<td>Recall</td>
<td>召回率</td>
<td>from sklearn.metrics import recall_score</td>
</tr>
<tr>
<td>F1</td>
<td>F1 值</td>
<td>from sklearn.metrics import f1_score</td>
</tr>
<tr>
<td>Confusion Matrix</td>
<td>混淆矩阵</td>
<td>from sklearn.metrics import confusion_matrix</td>
</tr>
<tr>
<td>ROC</td>
<td>ROC 曲线</td>
<td>from sklearn.metrics import roc</td>
</tr>
<tr>
<td>AUC</td>
<td>ROC 曲线下的面积</td>
<td>from sklearn.metrics import auc</td>
</tr>
</tbody>
</table>
<p>Scikit-learn 还允许在 GridSearchCV, RandomizedSearchCV 和 cross_validate 中评估 multiple metric （多个指数）。</p>
<p>接下来我们将对分类模型评价方法进行一个简单的应用。</p>
<h2 id="5-2-1-Iris-多分类"><a href="#5-2-1-Iris-多分类" class="headerlink" title="5.2.1 Iris 多分类"></a>5.2.1 Iris 多分类</h2><p>此案例选取的是著名的 Iris 数据集，建立了一个分类模型，该模型绘制了 ROC 曲线，运用了 AUC 评价指标。同时，为了更好地对其他评价指标进行学习，我们也在此模型中对其他评价指标进行了练习。</p>
<p>所使用的数据集是 Iris 数据集，这是机器学习中常用的分类实验数据集，由 Fisher 在 1936 年收集整理。Iris 也称鸢尾花卉数据集，包含 150 个数据集，分为 3 类，每类 50 个数据，每个数据包含 4 个属性。可通过花萼长度，花萼宽度，花瓣长度，花瓣宽度 4 个属性预测鸢尾花卉属于（Setosa，Versicolour，Virginica）三个种类中的哪一类。</p>
<p>先导入 iris 数据集，可以直接从 sklearn 里的 datasets 中加载。</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">from sklearn import metrics</span><br><span class="line"></span><br><span class="line">y = np.array([<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>])</span><br><span class="line">pred = np.array([<span class="number">0.1</span>,<span class="number">0.4</span>,<span class="number">0.35</span>,<span class="number">0.8</span>])</span><br><span class="line">fpr,tpr,thresholds = metrics.roc_curve(y,pred,pos_label=<span class="number">2</span>)</span><br><span class="line">metrics.auc(fpr,tpr)</span><br></pre></td></tr></table></figure>
<p>若是将 X，y 打印出来，可以看到 X 是一组二维的数组，而 y 是一维数组，且 y 中包含着三种标签。输出为：</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0<span class="selector-class">.75</span></span><br></pre></td></tr></table></figure>
<p>我们在加载数据集之后，加入一些随机数来增加训练集中的噪声以增加分类难度。</p>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import <span class="built_in">math</span></span><br><span class="line">def rmse(y_test, y): </span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">math</span>.<span class="built_in">sqrt</span>(<span class="built_in">math</span>.mean((y_test - y) ** <span class="number">2</span>))</span><br></pre></td></tr></table></figure>
<p>对训练集与测试集进行分割，并且打乱。</p>
<figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">def</span> <span class="selector-tag">R2</span>(y_test, y_true): </span><br><span class="line">    <span class="selector-tag">return</span> <span class="selector-tag">1</span> <span class="selector-tag">-</span> ((y_test - y_true)**<span class="number">2</span>)<span class="selector-class">.sum</span>() / ((y_true - y_true.mean())**<span class="number">2</span>)<span class="selector-class">.sum</span>()</span><br></pre></td></tr></table></figure>
<p>我们构建一个简单的分类器，即 svm，对鸢尾花的特征来进行分类。先利用 train_test_split 切割训练集和测试集并打乱排序，将分类器预测的标签记为 y_score。</p>
<figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from sklearn import datasets</span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">X = iris.data</span><br><span class="line">y = iris.target</span><br><span class="line">print X</span><br><span class="line">print y</span><br></pre></td></tr></table></figure>
<p>接下来就可以对预测所得到的结果进行评价，我们依次计算这个分类结果的准确率、召回率、F1-score、AUC，并且绘制 ROC 曲线。先计算模型准确率，accuracy_score 这个函数可以帮助我们计算，只需要输入 y 的真实标签的预测标签两个变量即可：</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">X = array([[<span class="number">5.1</span>, <span class="number">3.5</span>, <span class="number">1.4</span>, <span class="number">0.2</span>],</span><br><span class="line">       [<span class="number">4.9</span>, <span class="number">3.</span> , <span class="number">1.4</span>, <span class="number">0.2</span>],</span><br><span class="line">       [<span class="number">4.7</span>, <span class="number">3.2</span>, <span class="number">1.3</span>, <span class="number">0.2</span>],</span><br><span class="line">       [<span class="number">4.6</span>, <span class="number">3.1</span>, <span class="number">1.5</span>, <span class="number">0.2</span>],</span><br><span class="line">       [<span class="number">5.</span> , <span class="number">3.6</span>, <span class="number">1.4</span>, <span class="number">0.2</span>],</span><br><span class="line">       [<span class="number">5.4</span>, <span class="number">3.9</span>, <span class="number">1.7</span>, <span class="number">0.4</span>],</span><br><span class="line">       [<span class="number">4.6</span>, <span class="number">3.4</span>, <span class="number">1.4</span>, <span class="number">0.3</span>],</span><br><span class="line">       [<span class="number">5.</span> , <span class="number">3.4</span>, <span class="number">1.5</span>, <span class="number">0.2</span>],</span><br><span class="line">       [<span class="number">4.4</span>, <span class="number">2.9</span>, <span class="number">1.4</span>, <span class="number">0.2</span>],</span><br><span class="line">       [<span class="number">4.9</span>, <span class="number">3.1</span>, <span class="number">1.5</span>, <span class="number">0.1</span>],</span><br><span class="line">       [<span class="number">5.4</span>, <span class="number">3.7</span>, <span class="number">1.5</span>, <span class="number">0.2</span>],</span><br><span class="line">       [<span class="number">4.8</span>, <span class="number">3.4</span>, <span class="number">1.6</span>, <span class="number">0.2</span>],</span><br><span class="line">       [<span class="number">4.8</span>, <span class="number">3.</span> , <span class="number">1.4</span>, <span class="number">0.1</span>]</span><br><span class="line">       ……</span><br><span class="line">y = array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,</span><br><span class="line">       <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,</span><br><span class="line">       <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>,</span><br><span class="line">       <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>,</span><br><span class="line">       <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>,</span><br><span class="line">       <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>,</span><br><span class="line">       <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>])</span><br></pre></td></tr></table></figure>
<p>输出为：</p>
<figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">random_state = np.random.RandomState(1)</span><br><span class="line">n_samples, n_features = X.shape</span><br><span class="line">X = np.c_[X, random_state.randn(n_samples, 200 * n_features)]</span><br></pre></td></tr></table></figure>
<p>计算模型召回率、F1-score 和 AUC，召回率和 F1-score 的计算都很简单，与准确率的计算类似，但是 AUC 需要先计算取伪率和召回率。</p>
<figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_train, X_test, y_train, y_test = train_test_split<span class="params">(X, y, <span class="attr">test_size</span>=.3,<span class="attr">random_state</span>=0)</span></span><br></pre></td></tr></table></figure>
<p>输出为：</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn import svm</span><br><span class="line"><span class="keyword">from</span> sklearn.multiclass import OneVsRestClassifier</span><br><span class="line"></span><br><span class="line">classifier = OneVsRestClassifier(svm.SVC(<span class="attribute">kernel</span>=<span class="string">'linear'</span>, <span class="attribute">probability</span>=<span class="literal">True</span>,random_state=random_state))</span><br><span class="line">y_score = classifier.fit(X_train, y_train).decision_function(X_test)</span><br><span class="line">y_pred = classifier.predict(X_test)</span><br></pre></td></tr></table></figure>
<p>接下来绘制 ROC 曲线。figsize 参数指绘图对象的宽度和高度，在循环中调用 plt.plot 是为了各个分类离的 ROC 曲线，其中，fpr 和 tpr 即取伪率和召回率，分别是 ROC 曲线的横坐标和纵坐标，label 为图例。第二次调用 plt.plot 是为了绘制随机猜测的结果曲线，便于对比 ROC 结果。xlabel 和 ylabel 分别是横纵坐标名，title 为图片名称。</p>
<figure class="highlight coffeescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line">y_pred = svm.predict(X_test)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">'accuracy is %s'</span>%accuracy_score(y_true, y_pred))</span><br></pre></td></tr></table></figure>
<p>结果如图，ROC 曲线离虚线（即随机猜测的结果曲线）越远，则 AUC 越大。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/5401649-9da3f4af2c627e82.png" alt></p>
<p>最后附上完整代码</p>
<figure class="highlight actionscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">accuracy <span class="keyword">is</span> <span class="number">0.3111111111111111</span></span><br></pre></td></tr></table></figure>
<h2 id="5-2-2-多类-AdBoost-决策树"><a href="#5-2-2-多类-AdBoost-决策树" class="headerlink" title="5.2.2 多类 AdBoost 决策树"></a>5.2.2 多类 AdBoost 决策树</h2><p>此实例是通过随机生成的数据集，目的在于对两种迭代算法 SAMME.R 算法和 SAMME 算法进行比较，此处我们对于该模型的评价标准选取的是错误率，即 1 - 准确率。</p>
<p>首先我们载入需要的类库：</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics import recall_score</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics import f1_score</span><br><span class="line"></span><br><span class="line"><span class="builtin-name">print</span>(<span class="string">'precision is %s'</span>%svm.score(X_train, y_train)) </span><br><span class="line"><span class="builtin-name">print</span> (<span class="string">'recall is %s'</span>%recall_score(y_true, y_pred, <span class="attribute">average</span>=<span class="string">'macro'</span>))  </span><br><span class="line"><span class="builtin-name">print</span> (<span class="string">'F1-score is %s'</span>%f1_score(y_true, y_pred, <span class="attribute">average</span>=<span class="string">'macro'</span>) )</span><br><span class="line"><span class="comment">#  计算ROC曲线，并且为每一个分类计算AUC  </span></span><br><span class="line">fpr = dict()</span><br><span class="line">tpr = dict()</span><br><span class="line">roc_auc = dict()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(n_classes):</span><br><span class="line">    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])</span><br><span class="line">    roc_auc[i] = auc(fpr[i], tpr[i])</span><br><span class="line">    <span class="builtin-name">print</span> (<span class="string">'第%i种分类的roc：%f'</span>%(i,roc_auc[i]))</span><br></pre></td></tr></table></figure>
<p>这次的数据集是通过随机生成一些随机数据，来做二元分类。make_gaussian_quantiles 函数是通过采取多维标准正态分布和定义由嵌套同心多维球分离的类，生成分组多维正态分布的数据。我们共生成 13000 个样本，其中数据有 10 个样本特征，数据类别为 3 类。</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">precision is <span class="number">1.0</span></span><br><span class="line">recall is <span class="number">0.3737373737373737</span></span><br><span class="line">F1-score is <span class="number">0.4809941520467836</span></span><br><span class="line">第<span class="number">0</span>种分类的roc：<span class="number">0.952586</span></span><br><span class="line">第<span class="number">1</span>种分类的roc：<span class="number">0.598765</span></span><br><span class="line">第<span class="number">2</span>种分类的roc：<span class="number">0.775401</span></span><br></pre></td></tr></table></figure>
<p>将数据分割成训练集和测试集。其中 3000 个为训练集样本，10000 个为测试集样本。</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">colors = cycle([<span class="string">'aqua'</span>, <span class="string">'darkorange'</span>, <span class="string">'cornflowerblue'</span>])</span><br><span class="line"><span class="keyword">for</span> i, color <span class="keyword">in</span> zip(range(n_classes), colors):</span><br><span class="line">    plt.plot(fpr[i], tpr[i], <span class="attribute">color</span>=color, <span class="attribute">lw</span>=lw,</span><br><span class="line">             <span class="attribute">label</span>=<span class="string">'ROC curve of class &#123;0&#125; (area = &#123;1:0.2f&#125;)'</span></span><br><span class="line">             <span class="string">''</span>.format(i, roc_auc[i]))</span><br><span class="line"></span><br><span class="line">plt.plot([0, 1], [0, 1], <span class="string">'k--'</span>, <span class="attribute">lw</span>=lw)</span><br><span class="line">plt.xlim([0.0, 1.0])</span><br><span class="line">plt.ylim([0.0, 1.05])</span><br><span class="line">plt.xlabel(<span class="string">'False Positive Rate'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'True Positive Rate'</span>)</span><br><span class="line">plt.title(<span class="string">'Some extension of Receiver operating characteristic to multi-class'</span>)</span><br><span class="line">plt.legend(<span class="attribute">loc</span>=<span class="string">"lower right"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>Adaboost 是一种迭代算法，其核心思想是针对同一个训练集训练不同的分类器，然后把这些弱分类器集合起来，构成一个更强的最终分类器，即强分类器。AdaBoostClassifier 是 sklearn 中一个 AdaBoost 的分类框架，除了 AdaBoostClassifier，AdaBoostRegressor 用于回归。</p>
<p>这里我们分别选择了 SAMME.R 算法和 SAMME 算法，最多 600 个弱分类器，学习率分别是 1 和 1.5。SAMME.R 使用概率估计来更新模型，而 SAMME 仅仅使用分类。</p>
<p>训练模型并记录模型的错误率（1 - 准确率）。</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"><span class="keyword">from</span> itertools import cycle</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn import svm, datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics import roc_curve, auc</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection import train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing import label_binarize</span><br><span class="line"><span class="keyword">from</span> sklearn.multiclass import OneVsRestClassifier</span><br><span class="line"><span class="keyword">from</span> scipy import interp</span><br><span class="line"></span><br><span class="line"><span class="comment">#import sklearn里计算模型评价指标的相关函数</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入iris数据集</span></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">X = iris.data</span><br><span class="line">y = iris.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将标签二值化</span></span><br><span class="line">y = label_binarize(y, classes=[0, 1, 2])</span><br><span class="line">n_classes = y.shape[1]</span><br><span class="line"></span><br><span class="line"><span class="comment">#向数据集中加入噪声，增加分类的难度 </span></span><br><span class="line">random_state = np.random.RandomState(0)</span><br><span class="line">n_samples, n_features = X.shape</span><br><span class="line">X = np.c_[X, random_state.randn(n_samples, 200 * n_features)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将训练集和测试集打乱</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, <span class="attribute">test_size</span>=.3,</span><br><span class="line">                                                    <span class="attribute">random_state</span>=0)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构造一个简单的svm分类器</span></span><br><span class="line">classifier = OneVsRestClassifier(svm.SVC(<span class="attribute">kernel</span>=<span class="string">'linear'</span>, <span class="attribute">probability</span>=<span class="literal">True</span>,</span><br><span class="line">                                 <span class="attribute">random_state</span>=random_state))</span><br><span class="line"><span class="comment">#通过decision_function()计算得到的y_score的值，用在roc_curve()函数中</span></span><br><span class="line">y_score = classifier.fit(X_train, y_train).decision_function(X_test)</span><br><span class="line"></span><br><span class="line">y_pred = classifier.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算准确率</span></span><br><span class="line"><span class="builtin-name">print</span> (<span class="string">'accuracy is %s'</span>%accuracy_score(y_test, y_pred))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算精度</span></span><br><span class="line"><span class="builtin-name">print</span>(<span class="string">'precision is %s'</span>%classifier.score(X_train, y_train)) </span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算召回率</span></span><br><span class="line"><span class="builtin-name">print</span> (<span class="string">'recall is %s'</span>%recall_score(y_test, y_pred, <span class="attribute">average</span>=<span class="string">'macro'</span>))  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算f1-score</span></span><br><span class="line"><span class="builtin-name">print</span> (<span class="string">'F1-score is %s'</span>%f1_score(y_test, y_pred, <span class="attribute">average</span>=<span class="string">'macro'</span>) )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#  计算ROC曲线，并且为每一个分类计算AUC  </span></span><br><span class="line">fpr = dict()</span><br><span class="line">tpr = dict()</span><br><span class="line">roc_auc = dict()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(n_classes):</span><br><span class="line">    # 计算取伪率和召回率</span><br><span class="line">    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])</span><br><span class="line">    # 计算auc的值</span><br><span class="line">    roc_auc[i] = auc(fpr[i], tpr[i])</span><br><span class="line">    <span class="builtin-name">print</span> (<span class="string">'第%i种分类的roc：%f'</span>%(i,roc_auc[i]))</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制所有AUC曲线</span></span><br><span class="line">colors = cycle([<span class="string">'aqua'</span>, <span class="string">'darkorange'</span>, <span class="string">'cornflowerblue'</span>])</span><br><span class="line"><span class="keyword">for</span> i, color <span class="keyword">in</span> zip(range(n_classes), colors):</span><br><span class="line">    plt.plot(fpr[i], tpr[i], <span class="attribute">color</span>=color, <span class="attribute">lw</span>=lw,</span><br><span class="line">             <span class="attribute">label</span>=<span class="string">'ROC curve of class &#123;0&#125; (area = &#123;1:0.2f&#125;)'</span></span><br><span class="line">             <span class="string">''</span>.format(i, roc_auc[i]))</span><br><span class="line"></span><br><span class="line">plt.plot([0, 1], [0, 1], <span class="string">'k--'</span>, <span class="attribute">lw</span>=lw)</span><br><span class="line">plt.xlim([0.0, 1.0])</span><br><span class="line">plt.ylim([0.0, 1.05])</span><br><span class="line">plt.xlabel(<span class="string">'False Positive Rate'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'True Positive Rate'</span>)</span><br><span class="line">plt.title(<span class="string">'Some extension of Receiver operating characteristic to multi-class'</span>)</span><br><span class="line">plt.legend(<span class="attribute">loc</span>=<span class="string">"lower right"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>分别绘制 SAMME.R 算法和 SAMME 算法关于测试集错误率，训练集错误率，以及权重关于树的个数的变化图。figsize 参数为绘制图像的像素大小。</p>
<figure class="highlight xl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.externals.six.moves <span class="keyword">import</span> zip</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">from sklearn.datasets <span class="keyword">import</span> make_gaussian_quantiles</span><br><span class="line">from sklearn.ensemble <span class="keyword">import</span> AdaBoostClassifier</span><br><span class="line">from sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line">from sklearn.<span class="keyword">tree</span> <span class="keyword">import</span> DecisionTreeClassifier</span><br></pre></td></tr></table></figure>
<p>代码运行结果：</p>
<p><img src="http://upload-images.jianshu.io/upload_images/5401649-476412c4b8b8e1b9.png" alt></p>
<p>如图所示，SAMME.R 算法收敛速度比 SAMME 更快，在较低的迭代次数下实现了较低的测试误差。每一个 boosting 迭代后的测试集上的每个算法的误差都显示在左边，每个树的测试集上的分类错误在中间显示，并且在右边显示每个树的提升权重。所有的树在 SAMM.R 算法中都有一个权重，因此没有示出。</p>
<h2 id="5-3-3-模型概率校准"><a href="#5-3-3-模型概率校准" class="headerlink" title="5.3.3 模型概率校准"></a>5.3.3 模型概率校准</h2><p>执行分类时，我们常常希望不仅可以预测类标签，还要获得相应标签的概率。这个概率可以给我们一些预测的信心。一些模型可以提供部分的概率估计，有些模型甚至不支持概率预测。校准模块可以帮助我们更好地校准给定模型的概率，或者添加对概率预测的支持。该模型综合考虑了精度，召回率以及 F1-score。</p>
<p>首先导入模型所需的包。</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X, y = make_gaussian_quantiles(<span class="attribute">n_samples</span>=13000, <span class="attribute">n_features</span>=10,</span><br><span class="line">                               <span class="attribute">n_classes</span>=3, <span class="attribute">random_state</span>=1)</span><br></pre></td></tr></table></figure>
<p>实验在人工数据集上进行二分类，使用 make_classification 函数创建一个足够大的且特征较少的数据集，有 100000 个样本（其中有 1000 个样本用于模型训练），每个样本有 20 个样本特征，有 10 个冗余特征数，只有 2 个是具有信息的特征数。数据集利用 train_test_split 函数进行分割。</p>
<figure class="highlight inform7"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">n_split = 3000</span><br><span class="line"></span><br><span class="line">X_train, X_test = X<span class="comment">[:n_split]</span>, X<span class="comment">[n_split:]</span></span><br><span class="line">y_train, y_test = y<span class="comment">[:n_split]</span>, y<span class="comment">[n_split:]</span></span><br></pre></td></tr></table></figure>
<p>绘制校准曲线。</p>
<figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">bdt_real = AdaBoostClassifier(</span><br><span class="line">    DecisionTreeClassifier(max_depth=2),</span><br><span class="line">    n_estimators=600,</span><br><span class="line">    learning_rate=1)</span><br><span class="line"></span><br><span class="line">bdt_discrete = AdaBoostClassifier(</span><br><span class="line">    DecisionTreeClassifier(max_depth=2),</span><br><span class="line">    n_estimators=600,</span><br><span class="line">    learning_rate=1.5,</span><br><span class="line">    algorithm=<span class="string">"SAMME"</span>)</span><br><span class="line"></span><br><span class="line">bdt_real.fit(X_train, y_train)</span><br><span class="line">bdt_discrete.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">real_test_errors = []</span><br><span class="line">discrete_test_errors = []</span><br><span class="line"></span><br><span class="line">for real_test_predict, discrete_train_predict in zip(</span><br><span class="line">        bdt_real.staged_predict(X_test), bdt_discrete.staged_predict(X_test)):</span><br><span class="line">    real_test_errors.append(</span><br><span class="line">        1. - accuracy_score(real_test_predict, y_test))</span><br><span class="line">    discrete_test_errors.append(</span><br><span class="line">        1. - accuracy_score(discrete_train_predict, y_test))</span><br><span class="line"></span><br><span class="line">n_trees_discrete = len(bdt_discrete)</span><br><span class="line">n_trees_real = len(bdt_real)</span><br><span class="line"></span><br><span class="line">discrete_estimator_errors = bdt_discrete.estimator_errors_[:n_trees_discrete]</span><br><span class="line">real_estimator_errors = bdt_real.estimator_errors_[:n_trees_real]</span><br><span class="line">discrete_estimator_weights = bdt_discrete.estimator_weights_[:n_trees_discrete]</span><br></pre></td></tr></table></figure>
<p>各个模型输出结果为：</p>
<figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">plt</span><span class="selector-class">.figure</span>(figsize=(<span class="number">15</span>, <span class="number">5</span>))</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">plt</span><span class="selector-class">.subplot</span>(<span class="number">131</span>)</span><br><span class="line"><span class="selector-tag">plt</span><span class="selector-class">.plot</span>(range(<span class="number">1</span>, n_trees_discrete + <span class="number">1</span>),</span><br><span class="line">         discrete_test_errors, c=<span class="string">'black'</span>, label=<span class="string">'SAMME'</span>)</span><br><span class="line"><span class="selector-tag">plt</span><span class="selector-class">.plot</span>(range(<span class="number">1</span>, n_trees_real + <span class="number">1</span>),</span><br><span class="line">         real_test_errors, c=<span class="string">'black'</span>,</span><br><span class="line">         linestyle=<span class="string">'dashed'</span>, label=<span class="string">'SAMME.R'</span>)</span><br><span class="line"><span class="selector-tag">plt</span><span class="selector-class">.legend</span>()</span><br><span class="line"><span class="selector-tag">plt</span><span class="selector-class">.ylim</span>(<span class="number">0.18</span>, <span class="number">0.62</span>)</span><br><span class="line"><span class="selector-tag">plt</span><span class="selector-class">.ylabel</span>(<span class="string">'Test Error'</span>)</span><br><span class="line"><span class="selector-tag">plt</span><span class="selector-class">.xlabel</span>(<span class="string">'Number of Trees'</span>)</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">plt</span><span class="selector-class">.subplot</span>(<span class="number">132</span>)</span><br><span class="line"><span class="selector-tag">plt</span><span class="selector-class">.plot</span>(range(<span class="number">1</span>, n_trees_discrete + <span class="number">1</span>), discrete_estimator_errors,</span><br><span class="line">         <span class="string">"b"</span>, label=<span class="string">'SAMME'</span>, alpha=.<span class="number">5</span>)</span><br><span class="line"><span class="selector-tag">plt</span><span class="selector-class">.plot</span>(range(<span class="number">1</span>, n_trees_real + <span class="number">1</span>), real_estimator_errors,</span><br><span class="line">         <span class="string">"r"</span>, label=<span class="string">'SAMME.R'</span>, alpha=.<span class="number">5</span>)</span><br><span class="line"><span class="selector-tag">plt</span><span class="selector-class">.legend</span>()</span><br><span class="line"><span class="selector-tag">plt</span><span class="selector-class">.ylabel</span>(<span class="string">'Error'</span>)</span><br><span class="line"><span class="selector-tag">plt</span><span class="selector-class">.xlabel</span>(<span class="string">'Number of Trees'</span>)</span><br><span class="line"><span class="selector-tag">plt</span><span class="selector-class">.ylim</span>((.<span class="number">2</span>,</span><br><span class="line">         max(real_estimator_errors.max(),</span><br><span class="line">             discrete_estimator_errors.max()) * <span class="number">1.2</span>))</span><br><span class="line"><span class="selector-tag">plt</span><span class="selector-class">.xlim</span>((-<span class="number">20</span>, len(bdt_discrete) + <span class="number">20</span>))</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">plt</span><span class="selector-class">.subplot</span>(<span class="number">133</span>)</span><br><span class="line"><span class="selector-tag">plt</span><span class="selector-class">.plot</span>(range(<span class="number">1</span>, n_trees_discrete + <span class="number">1</span>), discrete_estimator_weights,</span><br><span class="line">         <span class="string">"b"</span>, label=<span class="string">'SAMME'</span>)</span><br><span class="line"><span class="selector-tag">plt</span><span class="selector-class">.legend</span>()</span><br><span class="line"><span class="selector-tag">plt</span><span class="selector-class">.ylabel</span>(<span class="string">'Weight'</span>)</span><br><span class="line"><span class="selector-tag">plt</span><span class="selector-class">.xlabel</span>(<span class="string">'Number of Trees'</span>)</span><br><span class="line"><span class="selector-tag">plt</span><span class="selector-class">.ylim</span>((<span class="number">0</span>, discrete_estimator_weights.max() * <span class="number">1.2</span>))</span><br><span class="line"><span class="selector-tag">plt</span><span class="selector-class">.xlim</span>((-<span class="number">20</span>, n_trees_discrete + <span class="number">20</span>))</span><br><span class="line"></span><br><span class="line"># <span class="selector-tag">prevent</span> <span class="selector-tag">overlapping</span> <span class="selector-tag">y-axis</span> <span class="selector-tag">labels</span></span><br><span class="line"><span class="selector-tag">plt</span><span class="selector-class">.subplots_adjust</span>(wspace=<span class="number">0.25</span>)</span><br><span class="line"><span class="selector-tag">plt</span><span class="selector-class">.show</span>()</span><br></pre></td></tr></table></figure>
<p><img src="http://upload-images.jianshu.io/upload_images/5401649-607039003ac26948.png" alt></p>
<p><img src="http://upload-images.jianshu.io/upload_images/5401649-4efc250b7dd2577a.png" alt></p>
<p>第一个图显示了用 Logistic 回归、高斯朴素贝叶斯和高斯朴素贝叶斯得到的估计概率，同时具有等渗校正和乙状结肠校正。这里可以观察到，逻辑回归被很好地校准，因为其曲线几乎是对角线。可以看出，高斯朴素贝叶斯的表现非常差，但是以线性 SVC 的方式也是如此. 尽管线性 SVC 显示了 sigmoid 校准曲线，但高斯朴素贝叶斯校准曲线具有转置的 sigmoid 结构。在这种情况下，分类器的过度自信是由违反朴素贝叶斯特征独立假设的冗余特征引起的。</p>
<p>第二个图显示了线性支持向量分类器（线性 SVC）的校准曲线。线性 SVC 显示了与高斯朴素贝叶斯相反的行为：线性 SVC 的校准曲线或可靠性图具有 sigmoid 曲线，这是一个典型的不够自信的分类器。在 LinearSVC 的情况下，这是 hinge loss 的边缘属性引起的，这使得模型集中在靠近决策边界（支持向量）的 hard samples（硬样本）上。这两种校准都可以解决这个问题，并产生几乎相同的结果。下图显示了高斯朴素贝叶斯在相同数据上的校准曲线，具有两种校准，也没有校准。</p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/算法/" rel="tag">#算法</a>
          
            <a href="/tags/模型/" rel="tag">#模型</a>
          
            <a href="/tags/评价方法/" rel="tag">#评价方法</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/blog/User_Behavior.html" rel="next" title="基于 Kafka 的服务端用户行为日志采集">
                <i class="fa fa-chevron-left"></i> 基于 Kafka 的服务端用户行为日志采集
              </a>
            
          </div>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/blog/Sklearn_PCA_Dimension_Reduction.html" rel="prev" title="Sklearn中的pca降维">
                Sklearn中的pca降维 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image" src="/uploads/tx.jpg" alt="LuisStruggle">
          <p class="site-author-name" itemprop="name">LuisStruggle</p>
          <p class="site-description motion-element" itemprop="description">Learning and communication</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">95</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">8</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">211</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/LuisStruggle" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/easyteam/profile?rightmod=1&wvr=6&mod=personinfo&is_all=1" target="_blank" title="Weibo">
                  
                    <i class="fa fa-fw fa-weibo"></i>
                  
                  Weibo
                </a>
              </span>
            
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              友情链接
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="http://www.v2ex.com/" title="V2EX社区" target="_blank">V2EX社区</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://cnodejs.org/" title="Cnode社区" target="_blank">Cnode社区</a>
                </li>
              
            </ul>
          </div>
        

      </section>

      
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">
            
              
            
            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#第五章-模型评价方法"><span class="nav-number">1.</span> <span class="nav-text">第五章 模型评价方法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#5-1-模型的评价方法介绍"><span class="nav-number">1.1.</span> <span class="nav-text">5.1 模型的评价方法介绍</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-2-项目实例运用"><span class="nav-number">1.2.</span> <span class="nav-text">5.2 项目实例运用</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-1-1-准确率"><span class="nav-number">1.3.</span> <span class="nav-text">5.1.1 准确率</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-1-2-精度"><span class="nav-number">1.4.</span> <span class="nav-text">5.1.2 精度</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-1-3-召回"><span class="nav-number">1.5.</span> <span class="nav-text">5.1.3 召回</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-1-4-F1"><span class="nav-number">1.6.</span> <span class="nav-text">5.1.4 F1</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-1-5-ROC"><span class="nav-number">1.7.</span> <span class="nav-text">5.1.5 ROC</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-1-6-回归模型评价指标"><span class="nav-number">1.8.</span> <span class="nav-text">5.1.6 回归模型评价指标</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-2-应用"><span class="nav-number">1.9.</span> <span class="nav-text">5.2 应用</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-2-1-Iris-多分类"><span class="nav-number">2.</span> <span class="nav-text">5.2.1 Iris 多分类</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-2-2-多类-AdBoost-决策树"><span class="nav-number">3.</span> <span class="nav-text">5.2.2 多类 AdBoost 决策树</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-3-3-模型概率校准"><span class="nav-number">4.</span> <span class="nav-text">5.3.3 模型概率校准</span></a></li></ol></div>
            
          </div>
        </section>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">
  
  &copy;  2012 - 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">LuisStruggle</span>
</div>

<!--
<div>
  <span>Email: 18300767078@163.com</span> | <span>主题 - <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next" target="_blank">NexT.Pisces</a></span>
</div>
-->

<!--
<div class="powered-by">
  由 <a class="theme-link" href="http://hexo.io">Hexo</a> 强力驱动 
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next" target="_blank">
    NexT.Pisces
  </a>
</div>
-->

        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.1"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.0.1"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.0.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.0.1"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.1"></script>



  



  




  
  

  

  

  

</body>
</html>
